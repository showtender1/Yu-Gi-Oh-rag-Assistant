from rag_store import retriever
from langchain_core.documents import Document
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_huggingface import HuggingFaceEmbeddings



def run_rag(cards, question):
    if not cards:
        return "í•´ë‹¹ ì¹´ë“œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    docs = [
        Document(
            page_content=c.get("desc", ""),
            metadata={"name": c.get("name", "")}
        )
        for c in cards
        if c.get("desc")
    ]

    if not docs:
        return "ì¹´ë“œ ì„¤ëª… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )

    # ğŸ”¥ í•µì‹¬ 1: Chromaë¥¼ in-memoryë¡œ ëª…ì‹œ
    db = Chroma.from_documents(
        documents=docs,
        embedding=embeddings,
        collection_name="yugioh_cards"
    )

    retriever = db.as_retriever()

    # ğŸ”¥ í•µì‹¬ 2: Gemini ì„¤ì •
    llm = ChatGoogleGenerativeAI(
        model="gemini-pro",
        convert_system_message_to_human=True
    )

    qa = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff"
    )

    return qa.run(question)
